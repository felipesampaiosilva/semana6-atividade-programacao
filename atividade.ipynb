{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1UX12-7SBfb",
        "outputId": "30c6a8ca-0edd-4074-97fa-4a35a026faef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 93.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 0.5578 Acc: 0.7418\n",
            "val Loss: 0.1996 Acc: 0.9150\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.3824 Acc: 0.8279\n",
            "val Loss: 0.2633 Acc: 0.8889\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.4951 Acc: 0.8402\n",
            "val Loss: 0.4846 Acc: 0.8235\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.6224 Acc: 0.7623\n",
            "val Loss: 0.6186 Acc: 0.7843\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.6065 Acc: 0.8156\n",
            "val Loss: 0.4387 Acc: 0.8366\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.7058 Acc: 0.7582\n",
            "val Loss: 0.3520 Acc: 0.8758\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.6321 Acc: 0.7418\n",
            "val Loss: 0.5584 Acc: 0.8039\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.4993 Acc: 0.8033\n",
            "val Loss: 0.2959 Acc: 0.8889\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.3509 Acc: 0.8648\n",
            "val Loss: 0.2361 Acc: 0.9020\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.3179 Acc: 0.8607\n",
            "val Loss: 0.2384 Acc: 0.8954\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.2527 Acc: 0.8934\n",
            "val Loss: 0.2541 Acc: 0.9020\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.3158 Acc: 0.8934\n",
            "val Loss: 0.2156 Acc: 0.9150\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.2270 Acc: 0.9139\n",
            "val Loss: 0.2070 Acc: 0.9150\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.2342 Acc: 0.9098\n",
            "val Loss: 0.2357 Acc: 0.9020\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.3023 Acc: 0.8484\n",
            "val Loss: 0.2205 Acc: 0.9216\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.2768 Acc: 0.8648\n",
            "val Loss: 0.2289 Acc: 0.9216\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.2756 Acc: 0.8811\n",
            "val Loss: 0.2158 Acc: 0.9085\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.2267 Acc: 0.9139\n",
            "val Loss: 0.2142 Acc: 0.9216\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.2268 Acc: 0.9057\n",
            "val Loss: 0.2090 Acc: 0.9281\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.3143 Acc: 0.8525\n",
            "val Loss: 0.2205 Acc: 0.9020\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.2538 Acc: 0.8852\n",
            "val Loss: 0.2172 Acc: 0.9150\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.2797 Acc: 0.8689\n",
            "val Loss: 0.2241 Acc: 0.9216\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.2194 Acc: 0.9180\n",
            "val Loss: 0.2052 Acc: 0.9281\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.2615 Acc: 0.8852\n",
            "val Loss: 0.2542 Acc: 0.9085\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.2534 Acc: 0.8975\n",
            "val Loss: 0.2019 Acc: 0.9346\n",
            "\n",
            "Training complete in 1m 26s\n",
            "Best val Acc: 0.934641\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from flask import Flask, request, jsonify\n",
        "from PIL import Image\n",
        "import io\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "# Baixando e preparando o dataset\n",
        "data_dir = 'data/hymenoptera_data'\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "    url = 'https://download.pytorch.org/tutorial/hymenoptera_data.zip'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    zip_path = os.path.join(data_dir, 'hymenoptera_data.zip')\n",
        "    open(zip_path, 'wb').write(r.content)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(data_dir)\n",
        "\n",
        "# Configurações do modelo e dataset\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Carregamento do modelo pré-treinado\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)\n",
        "\n",
        "# Salvando o modelo treinado\n",
        "torch.save(model_ft.state_dict(), 'model.pth')\n",
        "\n",
        "# Criação da API Flask\n",
        "app = Flask(__name__)\n",
        "\n",
        "def transform_image(image_bytes):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    image = Image.open(io.BytesIO(image_bytes))\n",
        "    return transform(image).unsqueeze(0)\n",
        "\n",
        "def get_prediction(image_bytes):\n",
        "    tensor = transform_image(image_bytes=image_bytes)\n",
        "    tensor = tensor.to(device)\n",
        "    model_ft.eval()\n",
        "    outputs = model_ft(tensor)\n",
        "    _, y_hat = outputs.max(1)\n",
        "    return class_names[y_hat]\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if request.method == 'POST':\n",
        "        file = request.files['file']\n",
        "        img_bytes = file.read()\n",
        "        class_name = get_prediction(image_bytes=img_bytes)\n",
        "        return jsonify({'class_name': class_name})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ]
    }
  ]
}